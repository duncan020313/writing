\documentclass[11pt, oneside]{article}      % use "amsart" instead of "article" for AMSLaTeX format
\usepackage{kotex}
\title{The Gap Between the Lab and the Real World}
\author{Dongjae Lee}
\date{2025.08.29}
\begin{document}
\maketitle


\begin{abstract}
	The gap between the lab and the real world is huge and rugged.
	Even outstanding research results often prove hard to apply in practice.
	Once a technology leaves the lab, requirements for reliability or yield become much higher.
	AI, too, has often disappointed by failing to meet real-world reliability thresholds.
	Methods for securing AI reliability will be decisive for its future.
\end{abstract}

Last week, at Security@KAIST, I saw research that detected fake powdered milk  by measuring droplet curvature.
The technology is highly useful and widely needed, yet it has not made it out of the lab.
According to the researcher, food-related technologies require approval from the relevant institute, and they gave up because the required reliability was at least 99.99\%.

This issue is not unique to food; it sits between research and reality across fields.
Software faces it as well—perhaps less severely—but production software is still held to tougher tests.
AI soars in labs and on benchmarks, yet adoption remains slow in high-stakes domains.

If robust methods emerge to secure AI reliability, the technology will spread far faster across society.
Otherwise, AI will fall short of expectations, and we may face another AI winter.

Assuring the safety and reliability of opaque software (e.g., LLMs) remains largely unexplored in computer science.
Because, until now, software has been written as source code with explicit and formally defined meaning.
But the new kind, composed of enormous matrices, resists understanding and defies prediction.
It is time to decide from what perspective—and how—we will reason about and control this new type of software.

\end{document}